{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning A-Z Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1_Data Preprocessing\n",
    "# Video_10: Importing the libraries\n",
    "\n",
    "## Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "------------------------------------\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "------------------------------------\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "# Video_11: Importing the dataset\n",
    "\n",
    "''' # Save the code we are going to write in SPYDER in the same folder\n",
    "where the .csv file is present (to avoid giving file path to .csv file)\n",
    "and then run the code. \n",
    "# Avoid giving path to the .csv file by going to the folder in terminal\n",
    "and then open Jupter notebook'''\n",
    "\n",
    "dataset= pd.read_csv('Data.csv')\n",
    "print(dataset)\n",
    "print('------------------------------------')\n",
    "# Now we need to create matrix of independent and dependent variable \n",
    "X=dataset.iloc[:,:-1].values # all independent variables\n",
    "y=dataset.iloc[:,-1].values # dependent variables\n",
    "# .values as we are trying to create an array\n",
    "print(X) # confirm it do NOT have dependent variable \n",
    "print('------------------------------------')\n",
    "print(y) # confirm it only contain  dependent variable\n",
    "print(X.ndim, y.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent variable is 'Purchased' here. Rest are independent variables. ML will use the independent variables to predict the dependent variable.\n",
    "\n",
    "Dependent variable: Purchased|\n",
    "Independent variable: Age, Salary, Purchased|\n",
    "Data preprocessing is common intitial step before starting ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python object priented programming:\\n    Class: is the model eg- construction plan\\n    Object: instance of the class. eg- House prepared from the construction plan\\n    method: is a tool use on the object to finish a task'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Python object priented programming:\n",
    "    Class: is the model eg- construction plan\n",
    "    Object: instance of the class. eg- House prepared from the construction plan\n",
    "    method: is a tool use on the object to finish a task'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video_13: Missing Data: We see 2 NaN \n",
    "\n",
    "# Strategy 1: Remove observation that contains NaN \n",
    "# Strategy 2: Replace Nan by mean of relevant column/row\n",
    "\n",
    "\n",
    "## Taking care of missing data in the correct way:\n",
    "from sklearn.preprocessing import Imputer # Imputer class\n",
    "\n",
    "# as we imported the class, we need to create an object of the class\n",
    "imputer = Imputer(missing_values= 'NaN', \n",
    "                  strategy= 'mean', axis=0) # Imputer object\n",
    "\n",
    "'''missing_values= 'NaN' because the dataset showed the missing values \n",
    "are denoted by NaN\n",
    "\n",
    "axis=0 mean value will be taken across the column and imputed\n",
    "axis=1 mean value will be taken across the row and imputed\n",
    "axis=0 is selcted as we are trying to replace NaN with mean value \n",
    "       across a feature/ column\n",
    "       '''\n",
    "\n",
    "# Fit imputer to matrix x (only where, missing data is present)\n",
    "imputer = imputer.fit(X[:,1:]) # 1: because 2nd and 3rd column has NaN values\n",
    "X[:,1:] = imputer.transform(X[:,1:]) #conversion of matrix x based on imputer\n",
    "X # see how NaN has been replaced with mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 categorical variables in the dataset Country (Independent) and\n",
    "Purchased (dependent). Country variable contains 3 categories and \n",
    "Purchase variable contains 2 categories. We want ONLY numbers for ML and\n",
    "not text (like in these vategorical features). Thus we need to convert the \n",
    "categories into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video_14: Categorical variables\n",
    "\n",
    "\n",
    "# Categorical variable: Country- 3 categories | Purchased-2 categories\n",
    "# Need to convert categories into numbers for ML \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X=LabelEncoder() # creating labelencoder object\n",
    "X[:,0]=labelencoder_X.fit_transform(X[:,0])\n",
    "# X[:,0] because only 1st column of X is categorical\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the country (categorical) column is converted into numerical. \n",
    "\n",
    "**But there is a huge PROBLEM.**\n",
    "3 categories of country column are converted into 0, 1, 2. Since 0 <1 <2, equations in the model will think that 1 country is bigger than other based on the number representing them. ML will think spain is bigger than germany as 2>0. BUT there is **no relational order between the countries**. \n",
    "\n",
    "Label encoder encode values without thinking whether there is order or not!\n",
    "\n",
    "But if we have 3 categories in the same column such as small, medium and large. Then 0,1,2 makes sense as **there is an order between small, medium and large**. But in country there is no order so we have to use something other than LabelEncoder.\n",
    "\n",
    "### Therefore we have to use  Dummy encoding in the case of country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0e+00, 0.0e+00, 0.0e+00, 4.4e+01, 7.2e+04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Dummy encoding will convert 1 country column into 3 columns because \n",
    "there are 3 categories. Each dummy variable column \n",
    "will represent 1 country. We need OneHotEncoder'''\n",
    "\n",
    "onehotencoder= OneHotEncoder(categorical_features=[0])\n",
    "# categorical_features is saying which column we want \n",
    "# to convert into dummy variable\n",
    "X=onehotencoder.fit_transform(X).toarray()\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously X had 3 columns. Now country column is replaced by 3 dummy variables or columns.\n",
    "So 3-1+3=5 columns. So OneHotEncoder worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for y or target or dependent variable\n",
    "# LabelEncoder is ok as y is a binary category i.e. \n",
    "# purchased or not, True and False\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video_16: Splitting the dataset into Training and Test set\n",
    "\n",
    "## Splitting the dataset into the Training and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be careful about ML algorithem understanding the correlation between X_train and\n",
    "y_train. If they don't understand the logic between X_train and y_train and just learn it by heart, \n",
    "it will have trouble predicting X_test. This is the case where overfitting of data happens. But there are \n",
    "regularization techniques to prevent this overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video_17: Feature scaling\n",
    "# Required becoz scale of features are uneven and widely varied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But generally FEATURE SCALING is extremely necessary: Look at the age range and salary range or scale (DATA PREPROCESSING EXAMPLE). Highly different.\n",
    "\n",
    "\n",
    "ML model depends on euclidian distance. Suppose there are 2 points, then they calculate\n",
    "euclidian distance by ((y2-y1)^2+(x2-x1)^2)^1/2. Now if one variable (suppose y) here salary\n",
    "has a way higher scale and then it is squared and added with other square (age here whose \n",
    "value is negligible even after squaring) then ML will only consider y value as it is so \n",
    "high and thus effect of age won't be considered.\n",
    "Now feature scaling can be done by\n",
    "\n",
    "1. STANDARIZARION: x_standarization= x - mean(x) / standard deviation(x)\n",
    "2. NORMALIZATION: x_normalization= x - min(x) / max(x) - min(x)\n",
    "\n",
    "So we need to standarize them such that each variable ranges from -1 to +1. \n",
    "And thus their high range wont affect ML model to be biased'''\n",
    "\n",
    "\n",
    "**CODE:**\n",
    "\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "\n",
    "X_test = sc_X.transform(X_test)'''\n",
    "\n",
    "If we have to standardscaler y, add the following code to the above code--\n",
    "\n",
    "'''\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "y_train = sc.y.fit_transform(y_train)\n",
    "'''\n",
    "\n",
    "\n",
    "For test set, we dont need to fit the sc_X instance because it's already fitted to training set\n",
    "That means X_test is transformed by StandardScaler based on its fitting to the X_train. So \n",
    "both X_train and X_test are fitted based on the same scale.\n",
    "Don't need to use feature scaling to y_train and y_test in this particular example. \n",
    "\n",
    "Here dependent variable or y\n",
    "is categorical as it has 1 or 0 values, we do NOT need to use feature scaling for clasification.\n",
    "\n",
    "But for regression where dependent variable or y can take a huge range/scale \n",
    "(unlike classification), we need to use feature scaling for y as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # StandardScaler class\n",
    "sc_X = StandardScaler() # creating sc_x, a StandardScaler object\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For X_test set, we dont need to fit the sc_X instance because it's already fitted to \n",
    "training set. That means X_test is transformed by StandardScaler based on its fitting \n",
    "to the X_train. So both X_train and X_test are fitted based on the same scale\n",
    "\n",
    "Don't need to use feature scaling to y_train and y_test. Here dependent variable or y\n",
    "is categorical as it has 1 or 0 values, we do NOT need to use feature scaling for clasification.\n",
    "This is classification as depenednt variable or target is categorical and therefor this is a \n",
    "classification problem.\n",
    "\n",
    "But for regression where dependent variable or y can take a huge range/scale unlike classification), \n",
    "we need to use feature scaling for y as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n",
      " [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n",
      " [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n",
      " [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n",
      " [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n",
      " [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n",
      "--------------------------------------------------------------\n",
      "[[-1.          2.64575131 -0.77459667 -1.45882927 -0.90166297]\n",
      " [-1.          2.64575131 -0.77459667  1.98496442  2.13981082]]\n",
      "--------------------------------------------------------------\n",
      "[1 1 1 0 1 0 0 1]\n",
      "--------------------------------------------------------------\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train) # All numbers range between -1 to +1 because of feature scaling\n",
    "print('--------------------------------------------------------------')\n",
    "print(X_test) # All numbers range between -1 to +1 because of feature scaling\n",
    "print('--------------------------------------------------------------')\n",
    "print(y_train) # No feature scaling for classification (classification because categorical dependent variable)\n",
    "print('--------------------------------------------------------------')\n",
    "print(y_test) # No feature scaling for classification (classification because categorical dependent variable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
